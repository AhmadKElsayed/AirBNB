{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4651,"databundleVersionId":35131,"sourceType":"competition"}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:46:39.271732Z","iopub.execute_input":"2025-04-19T01:46:39.272087Z","iopub.status.idle":"2025-04-19T01:46:39.281173Z","shell.execute_reply.started":"2025-04-19T01:46:39.272049Z","shell.execute_reply":"2025-04-19T01:46:39.280062Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nimport datetime\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport re\nfrom scipy.sparse import hstack\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n#sklearn\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, LabelBinarizer\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.metrics import accuracy_score, ndcg_score\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import plot_importance\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import RandomizedSearchCV","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:46:39.282304Z","iopub.execute_input":"2025-04-19T01:46:39.282689Z","iopub.status.idle":"2025-04-19T01:46:41.514893Z","shell.execute_reply.started":"2025-04-19T01:46:39.282627Z","shell.execute_reply":"2025-04-19T01:46:41.513914Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\n\n# Set a fixed seed value\nSEED = 42\n\n# Set seeds for reproducibility\nrandom.seed(SEED)\nnp.random.seed(SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:46:41.515794Z","iopub.execute_input":"2025-04-19T01:46:41.516427Z","iopub.status.idle":"2025-04-19T01:46:41.521087Z","shell.execute_reply.started":"2025-04-19T01:46:41.516389Z","shell.execute_reply":"2025-04-19T01:46:41.520170Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Reading Files:","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('../input/airbnb-recruiting-new-user-bookings/train_users_2.csv.zip')\ndf_test = pd.read_csv('../input/airbnb-recruiting-new-user-bookings/test_users.csv.zip')\ncountries = pd.read_csv('../input/airbnb-recruiting-new-user-bookings/countries.csv.zip')\nsessions = pd.read_csv('../input/airbnb-recruiting-new-user-bookings/sessions.csv.zip')\nage_gender = pd.read_csv('../input/airbnb-recruiting-new-user-bookings/age_gender_bkts.csv.zip')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:46:41.522095Z","iopub.execute_input":"2025-04-19T01:46:41.522383Z","iopub.status.idle":"2025-04-19T01:46:53.817877Z","shell.execute_reply.started":"2025-04-19T01:46:41.522360Z","shell.execute_reply":"2025-04-19T01:46:53.816845Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:46:53.820549Z","iopub.execute_input":"2025-04-19T01:46:53.820931Z","iopub.status.idle":"2025-04-19T01:46:53.841591Z","shell.execute_reply.started":"2025-04-19T01:46:53.820905Z","shell.execute_reply":"2025-04-19T01:46:53.840592Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:46:53.843799Z","iopub.execute_input":"2025-04-19T01:46:53.844179Z","iopub.status.idle":"2025-04-19T01:46:53.860197Z","shell.execute_reply.started":"2025-04-19T01:46:53.844143Z","shell.execute_reply":"2025-04-19T01:46:53.859155Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sessions.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:46:53.861235Z","iopub.execute_input":"2025-04-19T01:46:53.861555Z","iopub.status.idle":"2025-04-19T01:46:53.882415Z","shell.execute_reply.started":"2025-04-19T01:46:53.861531Z","shell.execute_reply":"2025-04-19T01:46:53.881328Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EDA:","metadata":{"_kg_hide-input":false}},{"cell_type":"code","source":"df_train.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:46:53.883546Z","iopub.execute_input":"2025-04-19T01:46:53.883917Z","iopub.status.idle":"2025-04-19T01:46:53.937322Z","shell.execute_reply.started":"2025-04-19T01:46:53.883889Z","shell.execute_reply":"2025-04-19T01:46:53.936183Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:46:53.938367Z","iopub.execute_input":"2025-04-19T01:46:53.938701Z","iopub.status.idle":"2025-04-19T01:46:54.083053Z","shell.execute_reply.started":"2025-04-19T01:46:53.938646Z","shell.execute_reply":"2025-04-19T01:46:54.082048Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:46:54.084350Z","iopub.execute_input":"2025-04-19T01:46:54.084712Z","iopub.status.idle":"2025-04-19T01:46:54.129391Z","shell.execute_reply.started":"2025-04-19T01:46:54.084677Z","shell.execute_reply":"2025-04-19T01:46:54.128393Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:46:54.130246Z","iopub.execute_input":"2025-04-19T01:46:54.130512Z","iopub.status.idle":"2025-04-19T01:46:54.274593Z","shell.execute_reply.started":"2025-04-19T01:46:54.130489Z","shell.execute_reply":"2025-04-19T01:46:54.273551Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:46:54.275545Z","iopub.execute_input":"2025-04-19T01:46:54.275930Z","iopub.status.idle":"2025-04-19T01:46:54.318354Z","shell.execute_reply.started":"2025-04-19T01:46:54.275898Z","shell.execute_reply":"2025-04-19T01:46:54.317154Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train[(df_train['age'] >= 100) | (df_train['age'] <= 13)].value_counts().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:46:54.319439Z","iopub.execute_input":"2025-04-19T01:46:54.319843Z","iopub.status.idle":"2025-04-19T01:46:54.346424Z","shell.execute_reply.started":"2025-04-19T01:46:54.319805Z","shell.execute_reply":"2025-04-19T01:46:54.345520Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test[(df_test['age'] >= 100) | (df_test['age'] <= 13)].value_counts().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:46:54.347404Z","iopub.execute_input":"2025-04-19T01:46:54.347688Z","iopub.status.idle":"2025-04-19T01:46:54.361359Z","shell.execute_reply.started":"2025-04-19T01:46:54.347630Z","shell.execute_reply":"2025-04-19T01:46:54.360356Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.concat((df_train, df_test), axis=0, ignore_index=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:46:54.362346Z","iopub.execute_input":"2025-04-19T01:46:54.362643Z","iopub.status.idle":"2025-04-19T01:46:54.386074Z","shell.execute_reply.started":"2025-04-19T01:46:54.362618Z","shell.execute_reply":"2025-04-19T01:46:54.385035Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.set_context(\"talk\")\nsns.set_style(\"whitegrid\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:46:54.387096Z","iopub.execute_input":"2025-04-19T01:46:54.387360Z","iopub.status.idle":"2025-04-19T01:46:54.391843Z","shell.execute_reply.started":"2025-04-19T01:46:54.387337Z","shell.execute_reply":"2025-04-19T01:46:54.390788Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(14,8))\norder1 = df['country_destination'].value_counts().index\nsns.countplot(data = df, x = 'country_destination', order = order1, palette=sns.color_palette(\"Blues_r\", 12))\nplt.xlabel('Destination')\nplt.ylabel('Count')\nplt.title('Destination Distribution')\norder2 = df_train['country_destination'].value_counts()\n\nfor i in range(order2.shape[0]):\n    count = order2[i]\n    strt='{:0.1f}%'.format(100*count / df_train.shape[0])\n    plt.text(i,count+1000,strt,ha='center')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:46:54.392793Z","iopub.execute_input":"2025-04-19T01:46:54.393134Z","iopub.status.idle":"2025-04-19T01:46:54.958861Z","shell.execute_reply.started":"2025-04-19T01:46:54.393102Z","shell.execute_reply":"2025-04-19T01:46:54.957584Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(14,8))\norder1 = df['gender'].value_counts().index\nsns.countplot(data = df, x = 'gender', order = order1, palette=sns.color_palette(\"Blues_r\", n_colors=4))\nplt.xlabel('Gender')\nplt.ylabel('Count')\nplt.title('Gender Distribution')\norder2 = df['gender'].value_counts()\n\nfor i in range(order2.shape[0]):\n    count = order2[i]\n    strt='{:0.1f}%'.format(100*count / df.shape[0])\n    plt.text(i,count+1000,strt,ha='center')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:46:54.960088Z","iopub.execute_input":"2025-04-19T01:46:54.960493Z","iopub.status.idle":"2025-04-19T01:46:55.393543Z","shell.execute_reply.started":"2025-04-19T01:46:54.960454Z","shell.execute_reply":"2025-04-19T01:46:55.392527Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Ensure acc_year is extracted correctly\ndf['date_account_created'] = pd.to_datetime(df['date_account_created'], errors='coerce')\ndf['acc_year'] = df['date_account_created'].dt.year\n\n# Filter valid years\nyears = [2010, 2011, 2012, 2013, 2014]\ndf = df[df['acc_year'].isin(years)]\n\n# Group properly: count of affiliate_provider per year\nyearly_data = df.groupby('acc_year')['affiliate_provider'].count().reset_index()\n\n# Optional: enforce order\nyearsOrder = pd.api.types.CategoricalDtype(ordered=True, categories=years)\nyearly_data['acc_year'] = yearly_data['acc_year'].astype(yearsOrder)\n\n# Plot\nplt.figure(figsize=(14, 8))\nsns.set_style(\"whitegrid\")\nsns.set_context(\"talk\")\n\nsns.lineplot(data=yearly_data, x='acc_year', y='affiliate_provider', marker='o', color=sns.color_palette()[0])\n\nplt.title('Year-wise Affiliate Provider')\nplt.xlabel('Year')\nplt.ylabel('Count')\nplt.xticks(rotation=45)\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:46:55.398960Z","iopub.execute_input":"2025-04-19T01:46:55.399279Z","iopub.status.idle":"2025-04-19T01:46:56.101882Z","shell.execute_reply.started":"2025-04-19T01:46:55.399252Z","shell.execute_reply":"2025-04-19T01:46:56.100871Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(14,8))\ndf_age = df[df['age']<=120]\nsns.distplot(df_age, x= df_age['age']);\nplt.xlabel('Age')\nplt.title('Age Distribution')\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:46:56.105099Z","iopub.execute_input":"2025-04-19T01:46:56.105438Z","iopub.status.idle":"2025-04-19T01:46:57.245389Z","shell.execute_reply.started":"2025-04-19T01:46:56.105411Z","shell.execute_reply":"2025-04-19T01:46:57.244182Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(14, 6))\n\n# Get top 5 affiliate providers\ncounts = df['affiliate_provider'].value_counts().head(5)\ncounts_order = counts.index\n\n# Use reversed blue palette for top 5\npalette = sns.color_palette(\"Blues_r\", n_colors=5)\n\nsns.countplot(\n    y=df['affiliate_provider'],\n    order=counts_order,\n    palette=palette\n)\n\nplt.xlabel('Count')\nplt.ylabel('')  # Hide y-axis label\nplt.title('Top 5 Affiliate Provider Distribution')\n\n# Add percentage annotations\nfor i in range(counts.shape[0]):\n    plt.text(counts[i] + 5200, i + 0.17, f\"{counts[i]/df.shape[0]*100:0.2f}%\", ha='center', fontsize=9)\n\nsns.despine()\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:46:57.246358Z","iopub.execute_input":"2025-04-19T01:46:57.246622Z","iopub.status.idle":"2025-04-19T01:46:57.778111Z","shell.execute_reply.started":"2025-04-19T01:46:57.246599Z","shell.execute_reply":"2025-04-19T01:46:57.777166Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Count the occurrences of 'en' vs. other languages\nlang_counts = df['language'].value_counts()\nen_count = lang_counts.get('en', 0)\nother_count = lang_counts.sum() - en_count\n\n# Data for pie chart\nlabels = ['English', 'Other']\nsizes = [en_count, other_count]\n\n# Plot the pie chart\nplt.figure(figsize=(14, 8))\nplt.pie(sizes, labels=labels, autopct='%1.2f%%', startangle=90, \n        colors=sns.color_palette(\"Blues_r\", n_colors=2))  # Exploding English slice for emphasis\n\n# Add title and style, adjust y-position to raise the title\nplt.title('Language Distribution', fontsize=16, fontweight='bold', y=1.05)\nplt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\n# Show the plot\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:46:57.778886Z","iopub.execute_input":"2025-04-19T01:46:57.779149Z","iopub.status.idle":"2025-04-19T01:46:57.945251Z","shell.execute_reply.started":"2025-04-19T01:46:57.779126Z","shell.execute_reply":"2025-04-19T01:46:57.944244Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set figure size\nplt.figure(figsize=(14, 6))\n\n# Get the counts for the 'first_device_type' column\ncounts = df['first_device_type'].value_counts()\ncounts_order = counts.index\n\n# Use reversed blue palette for countplot\npalette = sns.color_palette(\"Blues_r\", n_colors=counts.shape[0])\n\n# Create the countplot\nsns.countplot(\n    y=df['first_device_type'],\n    order=counts_order,\n    palette=palette\n)\n\n# Set axis labels and title\nplt.xlabel('Count')\nplt.ylabel('')  # Hide y-axis label\nplt.title('First Device Type Distribution')\n\n# Add percentage annotations on the bars\nfor i in range(counts.shape[0]):\n    plt.text(counts[i] + 4000, i + 0.17, f\"{counts[i]/df.shape[0]*100:0.2f}%\", ha='center', fontsize=9)\n\n# Remove the top and right spines for a cleaner look\nsns.despine()\n\n# Adjust layout to avoid overlapping\nplt.tight_layout()\n\n# Show the plot\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:46:57.946209Z","iopub.execute_input":"2025-04-19T01:46:57.946490Z","iopub.status.idle":"2025-04-19T01:46:58.408581Z","shell.execute_reply.started":"2025-04-19T01:46:57.946466Z","shell.execute_reply":"2025-04-19T01:46:58.407486Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Ensure 'date_first_booking' is in datetime format\ndf['date_first_booking'] = pd.to_datetime(df['date_first_booking'], errors='coerce')\n\n# Set figure size\nplt.figure(figsize=(14, 6))\n\n# Extract month names\nmonths_freq = df['date_first_booking'].dropna().dt.month_name().str[:3]\n\n# Count the occurrences of each month\ncounts = months_freq.value_counts()\n\n# Order the counts by index (month name order)\ncounts_order = counts.index\n\n# Use a reversed color palette for the countplot\npalette = sns.color_palette(\"Blues_r\", n_colors=counts.shape[0])\n\n# Plot the count of bookings by month\nsns.countplot(x=months_freq, order=counts_order, palette=palette)\n\n# Set axis labels and title\nplt.xlabel('Booking Date Month')\nplt.ylabel('Count')\nplt.title('Booking Date Month Distribution')\n\n# Add percentage annotations on the bars\nfor i, count in enumerate(counts):\n    percentage = count / months_freq.shape[0] * 100\n    plt.text(i, count + 10, f\"{percentage:.2f}%\", ha='center', fontsize=9)\n\n# Remove the top and right spines for a cleaner look\nsns.despine()\n\n# Adjust layout to avoid overlapping\nplt.tight_layout()\n\n# Show the plot\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:46:58.409692Z","iopub.execute_input":"2025-04-19T01:46:58.410078Z","iopub.status.idle":"2025-04-19T01:46:58.911780Z","shell.execute_reply.started":"2025-04-19T01:46:58.410042Z","shell.execute_reply":"2025-04-19T01:46:58.910547Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set figure size\nplt.figure(figsize=(14, 8))\n\n# Extract the day of the week from 'date_first_booking'\nweek_days_freq = df['date_first_booking'].dropna().dt.day_name()\n\n# Count the occurrences of each weekday\ncounts = week_days_freq.value_counts()\n\n# Order the counts by weekday order\ncounts_order = counts.index\n\n# Plot the count of bookings by weekday with a reversed color palette\nsns.countplot(x=week_days_freq, order=counts_order, palette=sns.color_palette(\"Blues_r\", n_colors=counts.shape[0]))\n\n# Set axis labels and title with better styling\nplt.xlabel('Booking Date Week Day', fontsize=12)\nplt.ylabel('Count', fontsize=12)\nplt.title('Booking Date Week Day Distribution', fontsize=16, fontweight='bold')\n\n# Add percentage annotations on the bars with slight adjustments for clarity\nfor i in range(counts.shape[0]):\n    plt.text(i, counts[i] + 200, f\"{counts[i]/week_days_freq.shape[0]*100:0.2f}%\", ha='center', fontsize=15)\n\n# Remove the top and right spines for a cleaner look\nsns.despine()\n\n# Show the plot\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:46:58.912877Z","iopub.execute_input":"2025-04-19T01:46:58.913280Z","iopub.status.idle":"2025-04-19T01:46:59.330403Z","shell.execute_reply.started":"2025-04-19T01:46:58.913242Z","shell.execute_reply":"2025-04-19T01:46:59.329285Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set Seaborn style and context\nsns.set_style(\"whitegrid\")\nsns.set_context(\"talk\", font_scale=1.1)\n\n# Assuming df is your DataFrame and 'date_account_created' is the column you're plotting\nplt.figure(figsize=(14, 8))\n\n# Create the line plot with blue color\ndf['date_account_created'].value_counts().sort_index().plot(kind='line', linewidth=1.2, color='#1f77b4')  # Blue color\n\n# Set axis labels and title with appropriate style\nplt.xlabel('Account Creation Date', fontsize=12)\nplt.ylabel('Count', fontsize=12)\nplt.title('Account Creation Date Distribution', fontsize=16, fontweight='bold')\n\n# Remove the top and right spines for a cleaner look\nsns.despine()\n\n# Adjust layout to avoid overlapping\nplt.tight_layout()\n\n# Show the plot\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:46:59.331440Z","iopub.execute_input":"2025-04-19T01:46:59.331799Z","iopub.status.idle":"2025-04-19T01:46:59.847599Z","shell.execute_reply.started":"2025-04-19T01:46:59.331772Z","shell.execute_reply":"2025-04-19T01:46:59.846571Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set Seaborn style and context\nsns.set_style(\"whitegrid\")\nsns.set_context(\"talk\", font_scale=1.1)\n\n# Ensure datetime is parsed\ndf['date_account_created'] = pd.to_datetime(df['date_account_created'], errors='coerce')\n\n# Group by month\nmonthly_counts = df['date_account_created'].dt.to_period('M').value_counts().sort_index()\nmonthly_counts.index = monthly_counts.index.to_timestamp()  # Convert PeriodIndex to Timestamp for plotting\n\n# Plot\nplt.figure(figsize=(16, 8))\nmonthly_counts.plot(kind='line', linewidth=1.5, color='#1f77b4', marker='o')\n\n# Labels and title\nplt.xlabel('Month', fontsize=12)\nplt.ylabel('Number of Accounts Created', fontsize=12)\nplt.title('Monthly Account Creation Trend', fontsize=16, fontweight='bold')\nplt.xticks(rotation=45)\n\n# Clean look\nsns.despine()\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:46:59.848650Z","iopub.execute_input":"2025-04-19T01:46:59.849043Z","iopub.status.idle":"2025-04-19T01:47:00.293700Z","shell.execute_reply.started":"2025-04-19T01:46:59.849015Z","shell.execute_reply":"2025-04-19T01:47:00.292625Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Preprocessing:","metadata":{}},{"cell_type":"markdown","source":"## Dates:","metadata":{}},{"cell_type":"code","source":"def extract_date_features(df, column_name, prefix):\n    \"\"\"\n    Extracts year, month, and day features from a date column and drops the original column.\n    \n    Parameters:\n        df (pd.DataFrame): The DataFrame containing the date column.\n        column_name (str): The name of the date column to process.\n        prefix (str): The prefix for the new feature columns.\n    \n    Returns:\n        pd.DataFrame: DataFrame with extracted date features.\n    \"\"\"\n    df[column_name] = pd.to_datetime(df[column_name], format='%Y-%m-%d', errors='coerce')\n    df[f'{prefix}_year'] = df[column_name].dt.year\n    df[f'{prefix}_month'] = df[column_name].dt.month\n    df[f'{prefix}_day'] = df[column_name].dt.day\n    return df.drop(columns=[column_name])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:47:00.294806Z","iopub.execute_input":"2025-04-19T01:47:00.295102Z","iopub.status.idle":"2025-04-19T01:47:00.302450Z","shell.execute_reply.started":"2025-04-19T01:47:00.295076Z","shell.execute_reply":"2025-04-19T01:47:00.301376Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train = extract_date_features(df_train, 'date_account_created', 'dac')\ndf_test = extract_date_features(df_test, 'date_account_created', 'dac')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:47:00.303517Z","iopub.execute_input":"2025-04-19T01:47:00.303826Z","iopub.status.idle":"2025-04-19T01:47:00.435331Z","shell.execute_reply.started":"2025-04-19T01:47:00.303801Z","shell.execute_reply":"2025-04-19T01:47:00.434300Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.drop('date_first_booking', inplace = True, axis = 1)\ndf_test.drop('date_first_booking', inplace = True, axis = 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:47:00.436482Z","iopub.execute_input":"2025-04-19T01:47:00.436801Z","iopub.status.idle":"2025-04-19T01:47:00.499053Z","shell.execute_reply.started":"2025-04-19T01:47:00.436775Z","shell.execute_reply":"2025-04-19T01:47:00.498094Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_timestamp_features(df, column_name):\n    \"\"\"\n    Extracts year, month, day, hour, minute, and second from a timestamp column.\n    \n    Parameters:\n        df (pd.DataFrame): DataFrame containing the timestamp column.\n        column_name (str): Name of the timestamp column to process.\n    \n    Returns:\n        pd.DataFrame: DataFrame with extracted features.\n    \"\"\"\n    # Ensure the column is a string\n    df[column_name] = df[column_name].astype(str)\n    \n    # Extract features\n    df[f'{column_name}_year'] = df[column_name].str[:4].astype(int)\n    df[f'{column_name}_month'] = df[column_name].str[4:6].astype(int)\n    df[f'{column_name}_day'] = df[column_name].str[6:8].astype(int)\n    df[f'{column_name}_hour'] = df[column_name].str[8:10].astype(int)\n    df[f'{column_name}_minute'] = df[column_name].str[10:12].astype(int)\n    df[f'{column_name}_second'] = df[column_name].str[12:14].astype(int)\n    \n    # Optionally, drop the original timestamp column\n    df = df.drop([column_name], axis=1)\n    \n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:47:00.500084Z","iopub.execute_input":"2025-04-19T01:47:00.500354Z","iopub.status.idle":"2025-04-19T01:47:00.508641Z","shell.execute_reply.started":"2025-04-19T01:47:00.500324Z","shell.execute_reply":"2025-04-19T01:47:00.507592Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train = extract_timestamp_features(df_train, 'timestamp_first_active')\ndf_test = extract_timestamp_features(df_test, 'timestamp_first_active')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:47:00.509635Z","iopub.execute_input":"2025-04-19T01:47:00.510091Z","iopub.status.idle":"2025-04-19T01:47:01.187557Z","shell.execute_reply.started":"2025-04-19T01:47:00.510049Z","shell.execute_reply":"2025-04-19T01:47:01.186750Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Sessions:","metadata":{}},{"cell_type":"code","source":"sessions = sessions.groupby(\"user_id\", as_index= False).agg(lambda x:x.tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:47:01.188468Z","iopub.execute_input":"2025-04-19T01:47:01.188735Z","iopub.status.idle":"2025-04-19T01:47:17.315178Z","shell.execute_reply.started":"2025-04-19T01:47:01.188711Z","shell.execute_reply":"2025-04-19T01:47:17.314113Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def convert_to_set(device):\n    device = [str(i) for i in device]\n    device = [re.sub(\"nan\",\"\",i) for i in device]\n    device = \",\".join(set(device))\n    \n    return device\n\ndef convert_the_time(time):\n    \n    float_time = []\n    time = [str(i) for i in time]\n    time = [re.sub(\"nan\",\"\",i) for i in time]\n    \n    for i in time:\n        try:\n            float_time.append(float(i))\n        except ValueError :\n            continue\n\n\n    time = sum(float_time)\n    \n    return time\n\ndef convert_to_string(action):\n    action = [str(i) for i in action]\n    action = [re.sub(\"nan\",\"\",i) for i in action]\n    action = \",\".join(action)\n    \n    return action","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:47:17.316229Z","iopub.execute_input":"2025-04-19T01:47:17.316479Z","iopub.status.idle":"2025-04-19T01:47:17.323688Z","shell.execute_reply.started":"2025-04-19T01:47:17.316455Z","shell.execute_reply":"2025-04-19T01:47:17.322764Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sessions[\"action\"] = sessions[\"action\"].apply(convert_to_string)\nsessions[\"action_type\"] = sessions[\"action_type\"].apply(convert_to_string)\nsessions[\"action_detail\"] = sessions[\"action_detail\"].apply(convert_to_string)\nsessions['device_type'] =sessions['device_type'].apply(convert_to_set)\nsessions['secs_elapsed'] = sessions['secs_elapsed'].apply(convert_the_time)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:47:17.324533Z","iopub.execute_input":"2025-04-19T01:47:17.324818Z","iopub.status.idle":"2025-04-19T01:48:13.709703Z","shell.execute_reply.started":"2025-04-19T01:47:17.324794Z","shell.execute_reply":"2025-04-19T01:48:13.708894Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sessions.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:48:13.710486Z","iopub.execute_input":"2025-04-19T01:48:13.710773Z","iopub.status.idle":"2025-04-19T01:48:13.722253Z","shell.execute_reply.started":"2025-04-19T01:48:13.710750Z","shell.execute_reply":"2025-04-19T01:48:13.721114Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Encoding:","metadata":{}},{"cell_type":"code","source":"X_df_train, X_df_val, y_train, y_val = train_test_split(df_train.drop(columns=['country_destination']), df_train['country_destination'],\n                                                        test_size=0.2, random_state=42, stratify=df_train['country_destination'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:48:13.723125Z","iopub.execute_input":"2025-04-19T01:48:13.723371Z","iopub.status.idle":"2025-04-19T01:48:14.068980Z","shell.execute_reply.started":"2025-04-19T01:48:13.723349Z","shell.execute_reply":"2025-04-19T01:48:14.068106Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Merging With Sessions:","metadata":{}},{"cell_type":"code","source":"X_df_train = X_df_train.merge(sessions, left_on='id', right_on='user_id', how='left')\nX_df_val = X_df_val.merge(sessions, left_on='id', right_on='user_id', how='left')\ndf_test = df_test.merge(sessions, left_on='id', right_on='user_id', how='left')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:48:14.069856Z","iopub.execute_input":"2025-04-19T01:48:14.070109Z","iopub.status.idle":"2025-04-19T01:48:14.550438Z","shell.execute_reply.started":"2025-04-19T01:48:14.070088Z","shell.execute_reply":"2025-04-19T01:48:14.549637Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Age:","metadata":{}},{"cell_type":"code","source":"'''\nX_df_train.loc[(X_df_train['age'] >= 100) | (X_df_train['age'] <= 15), 'age'] = np.nan\nX_df_val.loc[(X_df_val['age'] >= 100) | (X_df_val['age'] <= 15), 'age'] = np.nan\ndf_test.loc[(df_test['age'] >= 100) | (df_test['age'] <= 15), 'age'] = np.nan\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:48:14.551316Z","iopub.execute_input":"2025-04-19T01:48:14.551571Z","iopub.status.idle":"2025-04-19T01:48:14.557417Z","shell.execute_reply.started":"2025-04-19T01:48:14.551550Z","shell.execute_reply":"2025-04-19T01:48:14.556501Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_df_train.loc[(X_df_train['age'] >= 100) | (X_df_train['age'] <= 15), 'age'] = np.median(X_df_train['age'].dropna())\nX_df_val.loc[(X_df_val['age'] >= 100) | (X_df_val['age'] <= 15), 'age'] = np.median(X_df_train['age'].dropna())\ndf_test.loc[(df_test['age'] >= 100) | (df_test['age'] <= 15), 'age'] = np.median(df_train['age'].dropna())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:48:14.558404Z","iopub.execute_input":"2025-04-19T01:48:14.558645Z","iopub.status.idle":"2025-04-19T01:48:14.599245Z","shell.execute_reply.started":"2025-04-19T01:48:14.558625Z","shell.execute_reply":"2025-04-19T01:48:14.598285Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\n# Calculate mode once\nage_mode = X_df_train['age'].dropna().mode()[0]\n\n# Replace outliers in each dataset\nX_df_train.loc[(X_df_train['age'] >= 100) | (X_df_train['age'] <= 15), 'age'] = age_mode\nX_df_val.loc[(X_df_val['age'] >= 100) | (X_df_val['age'] <= 15), 'age'] = age_mode\ndf_test.loc[(df_test['age'] >= 100) | (df_test['age'] <= 15), 'age'] = age_mode\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:48:14.600146Z","iopub.execute_input":"2025-04-19T01:48:14.600391Z","iopub.status.idle":"2025-04-19T01:48:14.606298Z","shell.execute_reply.started":"2025-04-19T01:48:14.600369Z","shell.execute_reply":"2025-04-19T01:48:14.605235Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\nX_df_train.loc[(X_df_train['age'] >= 100), 'age'] = 100\nX_df_train.loc[(X_df_train['age'] <= 15), 'age'] = 15\n\nX_df_val.loc[(X_df_val['age'] >= 100), 'age'] = 100\nX_df_val.loc[(X_df_val['age'] <= 15), 'age'] = 15\n\ndf_test.loc[(df_test['age'] >= 100), 'age'] = 100\ndf_test.loc[(df_test['age'] <= 15), 'age'] = 15\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:48:14.607278Z","iopub.execute_input":"2025-04-19T01:48:14.607559Z","iopub.status.idle":"2025-04-19T01:48:14.622131Z","shell.execute_reply.started":"2025-04-19T01:48:14.607527Z","shell.execute_reply":"2025-04-19T01:48:14.621190Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def age_binning(age):\n    if 18 < age <= 20:\n        return '18 - 20'\n    elif 20 < age <= 25:\n        return '20 - 25'\n    elif 25 < age <= 30:\n        return '25 - 30'\n    elif 30 < age <= 35:\n        return '30 - 35'\n    elif 35 < age <= 40:\n        return '35 - 40'\n    elif 40 < age <= 45:\n        return '40 - 45'\n    elif 45 < age <= 50:\n        return '45 - 50'\n    elif 50 < age <= 55:\n        return '50 - 55'\n    elif 55 < age <= 60:\n        return '55 - 60'\n    elif 60 < age <= 65:\n        return '60 - 65'\n    elif 65 < age <= 70:\n        return '65 - 70'\n    elif 70 < age <= 75:\n        return '70 - 75'\n    elif 75 < age <= 80:\n        return '75 - 80'\n    elif 80 < age <= 85:\n        return '80 - 85'\n    elif 85 < age <= 90:\n        return '85 - 90'\n    elif 90 < age <= 95:\n        return '90 - 95'\n    elif 95 < age <= 100:\n        return '95 - 100'\n    else:\n        return np.nan","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:48:14.623058Z","iopub.execute_input":"2025-04-19T01:48:14.623382Z","iopub.status.idle":"2025-04-19T01:48:14.635504Z","shell.execute_reply.started":"2025-04-19T01:48:14.623356Z","shell.execute_reply":"2025-04-19T01:48:14.634700Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train['member_age_bins'] = df_train['age'].apply(age_binning)\ndf_test['member_age_bins'] = df_test['age'].apply(age_binning)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:48:14.636440Z","iopub.execute_input":"2025-04-19T01:48:14.636726Z","iopub.status.idle":"2025-04-19T01:48:14.851929Z","shell.execute_reply.started":"2025-04-19T01:48:14.636702Z","shell.execute_reply":"2025-04-19T01:48:14.850945Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_df_train.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:48:14.852995Z","iopub.execute_input":"2025-04-19T01:48:14.853265Z","iopub.status.idle":"2025-04-19T01:48:15.020729Z","shell.execute_reply.started":"2025-04-19T01:48:14.853240Z","shell.execute_reply":"2025-04-19T01:48:15.019876Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_df_val.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:48:15.021557Z","iopub.execute_input":"2025-04-19T01:48:15.021833Z","iopub.status.idle":"2025-04-19T01:48:15.072134Z","shell.execute_reply.started":"2025-04-19T01:48:15.021811Z","shell.execute_reply":"2025-04-19T01:48:15.071228Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Missing Strings:","metadata":{}},{"cell_type":"code","source":"def fill_missing_values(X_df_train, X_df_val, df_test, text_columns, numeric_column):\n    \"\"\"\n    Fills missing values in text columns with 'na' and in a numeric column with 0.\n\n    Args:\n        X_df_train (pd.DataFrame): Training dataframe.\n        X_df_val (pd.DataFrame): Validation dataframe.\n        df_test (pd.DataFrame): Test dataframe.\n        text_columns (list): List of text column names to fill with 'na'.\n        numeric_column (str): Name of numeric column to fill with 0.\n\n    Returns:\n        tuple: Transformed versions of (X_df_train, X_df_val, df_test)\n    \"\"\"\n    for df in [X_df_train, X_df_val, df_test]:\n        df[text_columns] = df[text_columns].fillna(\"na\")\n        df[numeric_column] = df[numeric_column].fillna(0)\n    \n    return X_df_train, X_df_val, df_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:48:15.072950Z","iopub.execute_input":"2025-04-19T01:48:15.073244Z","iopub.status.idle":"2025-04-19T01:48:15.078630Z","shell.execute_reply.started":"2025-04-19T01:48:15.073217Z","shell.execute_reply":"2025-04-19T01:48:15.077480Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### TF-IDF:","metadata":{}},{"cell_type":"code","source":"def tokens(x):\n    return x.split(',')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:48:15.079612Z","iopub.execute_input":"2025-04-19T01:48:15.080125Z","iopub.status.idle":"2025-04-19T01:48:15.093469Z","shell.execute_reply.started":"2025-04-19T01:48:15.080088Z","shell.execute_reply":"2025-04-19T01:48:15.092638Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def fit_transform_tfidf(X_df_train, X_df_val, df_test, columns):\n    \"\"\"\n    Fits a TF-IDF vectorizer on selected text columns of X_df_train and transforms X_df_val & df_test.\n    Adds transformed features to the original dataframes and removes the original text columns.\n\n    Args:\n        X_df_train (pd.DataFrame): Training dataframe.\n        X_df_val (pd.DataFrame): Validation dataframe.\n        df_test (pd.DataFrame): Test dataframe.\n        columns (list): List of text column names to apply TF-IDF.\n\n    Returns:\n        tuple: Transformed versions of (X_df_train, X_df_val, df_test)\n    \"\"\"\n    vectorizers = {}  # Store vectorizers for each column\n    transformed_data = {'train': [], 'val': [], 'test': []}\n\n    for col in columns:\n        vectorizer = TfidfVectorizer(min_df= 10, max_features = 5000, tokenizer = tokens)\n        X_train_tfidf = vectorizer.fit_transform(X_df_train[col].astype(str))  # Fit on training data\n        X_val_tfidf = vectorizer.transform(X_df_val[col].astype(str))  # Transform validation data\n        X_test_tfidf = vectorizer.transform(df_test[col].astype(str))  # Transform test data\n\n        vectorizers[col] = vectorizer\n        transformed_data['train'].append(X_train_tfidf)\n        transformed_data['val'].append(X_val_tfidf)\n        transformed_data['test'].append(X_test_tfidf)\n\n    # Stack transformed columns horizontally\n    X_train_tfidf = hstack(transformed_data['train'])\n    X_val_tfidf = hstack(transformed_data['val'])\n    X_test_tfidf = hstack(transformed_data['test'])\n\n    # Convert sparse matrices to DataFrame\n    train_tfidf_df = pd.DataFrame(X_train_tfidf.toarray(), index=X_df_train.index)\n    val_tfidf_df = pd.DataFrame(X_val_tfidf.toarray(), index=X_df_val.index)\n    test_tfidf_df = pd.DataFrame(X_test_tfidf.toarray(), index=df_test.index)\n\n    # Concatenate new TF-IDF features with original dataframe (excluding original text columns)\n    X_df_train = pd.concat([X_df_train.drop(columns, axis=1), train_tfidf_df], axis=1)\n    X_df_val = pd.concat([X_df_val.drop(columns, axis=1), val_tfidf_df], axis=1)\n    df_test = pd.concat([df_test.drop(columns, axis=1), test_tfidf_df], axis=1)\n\n    return X_df_train, X_df_val, df_test\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:48:15.094386Z","iopub.execute_input":"2025-04-19T01:48:15.094747Z","iopub.status.idle":"2025-04-19T01:48:15.106611Z","shell.execute_reply.started":"2025-04-19T01:48:15.094711Z","shell.execute_reply":"2025-04-19T01:48:15.105733Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"columns_to_vectorize = ['action', 'action_type', 'action_detail']\nX_df_train, X_df_val, df_test = fit_transform_tfidf(X_df_train, X_df_val, df_test, columns_to_vectorize)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:48:15.107564Z","iopub.execute_input":"2025-04-19T01:48:15.107943Z","iopub.status.idle":"2025-04-19T01:48:31.192058Z","shell.execute_reply.started":"2025-04-19T01:48:15.107907Z","shell.execute_reply":"2025-04-19T01:48:31.191023Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_id = X_df_train['id']\nval_id = X_df_val['id']\ntest_id = df_test['id']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:48:31.193016Z","iopub.execute_input":"2025-04-19T01:48:31.193304Z","iopub.status.idle":"2025-04-19T01:48:31.198591Z","shell.execute_reply.started":"2025-04-19T01:48:31.193281Z","shell.execute_reply":"2025-04-19T01:48:31.197328Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train = X_df_train.drop(columns=['id', 'user_id'], inplace=False)\nX_val = X_df_val.drop(columns=['id', 'user_id'], inplace=False)\nX_test = df_test.drop(columns=['id', 'user_id'], inplace=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:48:31.199499Z","iopub.execute_input":"2025-04-19T01:48:31.199832Z","iopub.status.idle":"2025-04-19T01:48:31.467539Z","shell.execute_reply.started":"2025-04-19T01:48:31.199805Z","shell.execute_reply":"2025-04-19T01:48:31.466717Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def encode_categorical_features(X_train, X_val, X_test, cat_cols):\n    \"\"\"\n    Encodes categorical features using One-Hot Encoding (OHE) for low-cardinality features\n    and Label Encoding for high-cardinality features.\n\n    Parameters:\n        X_train (DataFrame): Training data\n        X_val (DataFrame): Validation data\n        X_test (DataFrame): Test data\n        cat_cols (list): List of categorical column names\n\n    Returns:\n        X_train, X_val, X_test (DataFrame): Transformed datasets\n        label_encoders (dict): Dictionary of label encoders for high-cardinality features\n    \"\"\"\n\n    # Ensure categorical columns exist in all datasets\n    cat_cols = [col for col in cat_cols if col in X_train.columns]\n\n    # Separate columns based on the number of unique categories\n    one_hot_cols = [col for col in cat_cols if X_train[col].nunique() < 5]\n    label_encode_cols = [col for col in cat_cols if X_train[col].nunique() >= 5]\n\n    # One-Hot Encoding for low-cardinality features\n    if one_hot_cols:\n        ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n        X_train_ohe = pd.DataFrame(ohe.fit_transform(X_train[one_hot_cols]), \n                                   columns=ohe.get_feature_names_out(one_hot_cols))\n        X_val_ohe = pd.DataFrame(ohe.transform(X_val[one_hot_cols]), \n                                 columns=ohe.get_feature_names_out(one_hot_cols))\n        X_test_ohe = pd.DataFrame(ohe.transform(X_test[one_hot_cols]), \n                                  columns=ohe.get_feature_names_out(one_hot_cols))\n        # Drop original categorical columns and merge OHE results\n        X_train = X_train.drop(columns=one_hot_cols, errors='ignore').reset_index(drop=True).join(X_train_ohe)\n        X_val = X_val.drop(columns=one_hot_cols, errors='ignore').reset_index(drop=True).join(X_val_ohe)\n        X_test = X_test.drop(columns=one_hot_cols, errors='ignore').reset_index(drop=True).join(X_test_ohe)\n\n    # Label Encoding for high-cardinality features\n    label_encoders = {}\n    for col in label_encode_cols:\n        le = LabelEncoder()\n        X_train[col] = le.fit_transform(X_train[col].astype(str))\n        X_val[col] = X_val[col].map(lambda x: le.transform([x])[0] if x in le.classes_ else -1)\n        X_test[col] = X_test[col].map(lambda x: le.transform([x])[0] if x in le.classes_ else -1)\n        label_encoders[col] = le  # Store encoder for inverse transform if needed\n\n    return X_train, X_val, X_test, label_encoders\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:48:31.468540Z","iopub.execute_input":"2025-04-19T01:48:31.468933Z","iopub.status.idle":"2025-04-19T01:48:31.478100Z","shell.execute_reply.started":"2025-04-19T01:48:31.468896Z","shell.execute_reply":"2025-04-19T01:48:31.476988Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cat_cols = ['gender', 'signup_method', 'language', 'affiliate_channel', \n            'affiliate_provider', 'first_affiliate_tracked', 'signup_app', \n            'first_device_type', 'first_browser', 'member_age_bins', 'device_type',]\n\n# Encode categorical features for all datasets\nX_train, X_val, X_test, label_encoders = encode_categorical_features(X_train, X_val, X_test, cat_cols)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:48:31.478997Z","iopub.execute_input":"2025-04-19T01:48:31.479359Z","iopub.status.idle":"2025-04-19T01:49:33.035150Z","shell.execute_reply.started":"2025-04-19T01:48:31.479333Z","shell.execute_reply":"2025-04-19T01:49:33.034103Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Imbalance","metadata":{}},{"cell_type":"code","source":"class_distribution = y_train.value_counts()\n\n# Get the proportion of each class\nclass_proportions = y_train.value_counts(normalize=True)*100\nprint(class_proportions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:49:33.036195Z","iopub.execute_input":"2025-04-19T01:49:33.036479Z","iopub.status.idle":"2025-04-19T01:49:33.084102Z","shell.execute_reply.started":"2025-04-19T01:49:33.036456Z","shell.execute_reply":"2025-04-19T01:49:33.083030Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label_encoder = LabelEncoder()\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_val_encoded = label_encoder.transform(y_val)\n\nprint(\"Encoded y_train:\", y_val_encoded[:5])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:49:33.085157Z","iopub.execute_input":"2025-04-19T01:49:33.085541Z","iopub.status.idle":"2025-04-19T01:49:33.162493Z","shell.execute_reply.started":"2025-04-19T01:49:33.085507Z","shell.execute_reply":"2025-04-19T01:49:33.161419Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_test.drop(['member_age_bins'], axis = 1, inplace = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:49:33.163760Z","iopub.execute_input":"2025-04-19T01:49:33.164120Z","iopub.status.idle":"2025-04-19T01:49:33.237512Z","shell.execute_reply.started":"2025-04-19T01:49:33.164086Z","shell.execute_reply":"2025-04-19T01:49:33.236482Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model:","metadata":{}},{"cell_type":"markdown","source":"### XGBoost:","metadata":{}},{"cell_type":"code","source":"xgb = XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.5, gamma=0, gpu_id=-1,\n              importance_type='gain', interaction_constraints=None,\n              learning_rate=0.3, max_delta_step=0, max_depth=6,\n              min_child_weight=1, missing=np.nan, monotone_constraints=None,\n              n_estimators=25, n_jobs=0, num_parallel_tree=1,\n              objective='multi:softprob', random_state=42, reg_alpha=0,\n              reg_lambda=1, scale_pos_weight=None, seed=0, subsample=0.5,\n              tree_method=None, validate_parameters=False, verbosity=None)\n\nxgb.fit(X_train, y_train_encoded)\n\ny_predxgb = xgb.predict_proba(X_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:49:33.238196Z","iopub.execute_input":"2025-04-19T01:49:33.238461Z","iopub.status.idle":"2025-04-19T01:50:18.528425Z","shell.execute_reply.started":"2025-04-19T01:49:33.238439Z","shell.execute_reply":"2025-04-19T01:50:18.526867Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ids = []\ncts = []\nfor i in range(len(test_id)):\n    idx = test_id[i]\n    ids += [idx] * 5\n    cts += label_encoder.inverse_transform(np.argsort(y_predxgb[i])[::-1])[:5].tolist()\n\nsubxgb = pd.DataFrame(np.column_stack((ids, cts)), columns=['id', 'country'])\nsubxgb.to_csv('submission_xgb.csv',index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:50:18.529232Z","iopub.execute_input":"2025-04-19T01:50:18.529501Z","iopub.status.idle":"2025-04-19T01:50:27.393692Z","shell.execute_reply.started":"2025-04-19T01:50:18.529475Z","shell.execute_reply":"2025-04-19T01:50:27.392687Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### LightGBM:","metadata":{}},{"cell_type":"code","source":"lgb = LGBMClassifier(\n    max_depth=7, \n    num_leaves=40,\n    min_child_samples=12,\n    min_split_gain=0.0,\n    learning_rate=0.02,\n    n_estimators=140,\n    verbosity=-1,\n    random_state = 42\n\n)\n\nlgb.fit(\n    X_train, y_train_encoded,\n    #eval_set=[(X_val, y_val_encoded)],\n    #early_stopping_rounds=10\n )\n\ny_predlgb = lgb.predict_proba(X_test)\nprint(\"Done!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:50:27.394623Z","iopub.execute_input":"2025-04-19T01:50:27.394929Z","iopub.status.idle":"2025-04-19T01:51:38.207620Z","shell.execute_reply.started":"2025-04-19T01:50:27.394897Z","shell.execute_reply":"2025-04-19T01:51:38.205635Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ids = []\ncts = []\nfor i in range(len(test_id)):\n    idx = test_id[i]\n    ids += [idx] * 5\n    cts += label_encoder.inverse_transform(np.argsort(y_predlgb[i])[::-1])[:5].tolist()\n\nsublgb = pd.DataFrame(np.column_stack((ids, cts)), columns=['id', 'country'])\nsublgb.to_csv('submission_lgb.csv',index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:51:38.221259Z","iopub.execute_input":"2025-04-19T01:51:38.221714Z","iopub.status.idle":"2025-04-19T01:51:49.266471Z","shell.execute_reply.started":"2025-04-19T01:51:38.221674Z","shell.execute_reply":"2025-04-19T01:51:49.264984Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Random Forrest:","metadata":{}},{"cell_type":"code","source":"# Ensure all column names are strings\nX_train.columns = X_train.columns.astype(str)\nX_test.columns = X_test.columns.astype(str)\n\n# Fill NaNs with -1\nimputer = SimpleImputer(strategy='constant', fill_value=-1)\nX_train_imputed = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\nX_test_imputed = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:51:49.268596Z","iopub.execute_input":"2025-04-19T01:51:49.269052Z","iopub.status.idle":"2025-04-19T01:51:52.967008Z","shell.execute_reply.started":"2025-04-19T01:51:49.269021Z","shell.execute_reply":"2025-04-19T01:51:52.965822Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fit the model\nrf = RandomForestClassifier(\n    n_estimators=40,\n    max_depth=3,\n    min_samples_split=10,\n    min_samples_leaf=4,\n    max_features=None,\n    bootstrap=True,\n    random_state = 42\n)\nrf.fit(X_train_imputed, y_train_encoded)\n\n# Predict\ny_predrf = rf.predict_proba(X_test_imputed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:51:52.968350Z","iopub.execute_input":"2025-04-19T01:51:52.968648Z","iopub.status.idle":"2025-04-19T01:53:07.053342Z","shell.execute_reply.started":"2025-04-19T01:51:52.968624Z","shell.execute_reply":"2025-04-19T01:53:07.052075Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ids = []\ncts = []\nfor i in range(len(test_id)):\n    idx = test_id[i]\n    ids += [idx] * 5\n    cts += label_encoder.inverse_transform(np.argsort(y_predrf[i])[::-1])[:5].tolist()\n\nsubrf = pd.DataFrame(np.column_stack((ids, cts)), columns=['id', 'country'])\nsubrf.to_csv('submission_rf.csv',index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:53:07.054503Z","iopub.execute_input":"2025-04-19T01:53:07.054867Z","iopub.status.idle":"2025-04-19T01:53:15.967945Z","shell.execute_reply.started":"2025-04-19T01:53:07.054830Z","shell.execute_reply":"2025-04-19T01:53:15.966828Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"def compute_ndcg(y_true, y_pred, k=5):\n    \"\"\"\n    Computes the NDCG@k score for multi-class classification.\n\n    Parameters:\n        y_true (array-like): Ground truth labels, must be encoded as integers.\n        y_pred (array-like): Predicted probabilities (output of predict_proba).\n        k (int): The number of top predictions to consider for NDCG calculation.\n    \n    Returns:\n        float: The NDCG@k score.\n    \"\"\"\n    # Convert y_true to binary indicator format\n    label_binarizer = LabelBinarizer()\n    y_true_binarized = label_binarizer.fit_transform(y_true)\n\n    # Compute NDCG@k\n    ndcg_score_value = ndcg_score(y_true_binarized, y_pred, k=k)\n\n    return ndcg_score_value","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:53:15.968996Z","iopub.execute_input":"2025-04-19T01:53:15.969305Z","iopub.status.idle":"2025-04-19T01:53:15.974948Z","shell.execute_reply.started":"2025-04-19T01:53:15.969281Z","shell.execute_reply":"2025-04-19T01:53:15.973734Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred_train = lgb.predict_proba(X_train)\ny_pred_val = lgb.predict_proba(X_val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:53:15.976147Z","iopub.execute_input":"2025-04-19T01:53:15.976478Z","iopub.status.idle":"2025-04-19T01:53:49.001155Z","shell.execute_reply.started":"2025-04-19T01:53:15.976445Z","shell.execute_reply":"2025-04-19T01:53:49.000028Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ndcg_train_score = compute_ndcg(y_train_encoded, y_pred_train, k=5)\nprint(f\"NDCG@5 Score on Training Data: {ndcg_train_score:.4f}\")\n\nndcg_val_score = compute_ndcg(y_val_encoded, y_pred_val, k=5)\nprint(f\"NDCG@5 Score on Val Data: {ndcg_val_score:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:53:49.002394Z","iopub.execute_input":"2025-04-19T01:53:49.002822Z","iopub.status.idle":"2025-04-19T01:54:03.454184Z","shell.execute_reply.started":"2025-04-19T01:53:49.002779Z","shell.execute_reply":"2025-04-19T01:54:03.452735Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Calibration","metadata":{}},{"cell_type":"code","source":"'''\nfrom sklearn.calibration import CalibratedClassifierCV\n\n\n# 1. Calibrate with Platt Scaling (Sigmoid)\ncalibrator_platt = CalibratedClassifierCV(xgb, method='sigmoid', cv='prefit')\ncalibrator_platt.fit(X_val, y_val_encoded)  # Fit calibrator on validation set\ny_pred_platt = calibrator_platt.predict_proba(X_test)  # Calibrated probabilities\n\n# 2. Calibrate with Isotonic Regression\ncalibrator_isotonic = CalibratedClassifierCV(xgb, method='isotonic', cv='prefit')\ncalibrator_isotonic.fit(X_val, y_val_encoded)\ny_pred_isotonic = calibrator_isotonic.predict_proba(X_test)\n\n# Output calibrated probabilities\nprint(\"Calibrated Probabilities (Platt Scaling):\", y_pred_platt[:5])  # First 5 samples\nprint(\"Calibrated Probabilities (Isotonic):\", y_pred_isotonic[:5])\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:54:03.455201Z","iopub.execute_input":"2025-04-19T01:54:03.455548Z","iopub.status.idle":"2025-04-19T01:54:03.462902Z","shell.execute_reply.started":"2025-04-19T01:54:03.455522Z","shell.execute_reply":"2025-04-19T01:54:03.461742Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Submission:","metadata":{}},{"cell_type":"markdown","source":"### Ensemble:","metadata":{}},{"cell_type":"code","source":"# Define the weights for the models (you can adjust these based on the performance of the models)\nlgb_weight = 0.9 # weight for LightGM\nxgb_weight = 0.2 # weight for XGBoost\nrf_weight = 0.0  # weight for RandomForest\n\nids = []\ncts = []\n\n# Loop through each sample in the test set\nfor i in range(len(test_id)):\n    idx = test_id[i]\n    \n    # Get the weighted average of the predictions\n    weighted_pred = rf_weight * y_predrf[i] + xgb_weight * y_predxgb[i] + lgb_weight * y_predlgb[i] \n    \n    # Get the top 5 predicted classes\n    top_5_classes = label_encoder.inverse_transform(np.argsort(weighted_pred)[::-1])[:5].tolist()\n    \n    # Append the results\n    ids += [idx] * 5\n    cts += top_5_classes\n\n# Create the DataFrame and save it to a CSV file\nsuball = pd.DataFrame(np.column_stack((ids, cts)), columns=['id', 'country'])\nsuball.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:54:03.463979Z","iopub.execute_input":"2025-04-19T01:54:03.464257Z","iopub.status.idle":"2025-04-19T01:54:13.278766Z","shell.execute_reply.started":"2025-04-19T01:54:03.464233Z","shell.execute_reply":"2025-04-19T01:54:13.277740Z"}},"outputs":[],"execution_count":null}]}