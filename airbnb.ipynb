{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4651,"databundleVersionId":35131,"sourceType":"competition"}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport datetime\nimport warnings\nwarnings.filterwarnings('ignore')\nimport re\nfrom scipy.sparse import hstack\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n#sklearn\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, LabelBinarizer\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.metrics import accuracy_score, ndcg_score\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import plot_importance\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Reading Files:","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('../input/airbnb-recruiting-new-user-bookings/train_users_2.csv.zip')\ndf_test = pd.read_csv('../input/airbnb-recruiting-new-user-bookings/test_users.csv.zip')\ncountries = pd.read_csv('../input/airbnb-recruiting-new-user-bookings/countries.csv.zip')\nsessions = pd.read_csv('../input/airbnb-recruiting-new-user-bookings/sessions.csv.zip')\nage_gender = pd.read_csv('../input/airbnb-recruiting-new-user-bookings/age_gender_bkts.csv.zip')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sessions.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EDA:","metadata":{}},{"cell_type":"code","source":"df_train.describe()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.isna().sum()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test.isna().sum()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train[(df_train['age'] >= 100) | (df_train['age'] <= 13)].value_counts().sum()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test[(df_test['age'] >= 100) | (df_test['age'] <= 13)].value_counts().sum()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Preprocessing:","metadata":{}},{"cell_type":"markdown","source":"## Dates:","metadata":{}},{"cell_type":"code","source":"def extract_date_features(df, column_name, prefix):\n    \"\"\"\n    Extracts year, month, and day features from a date column and drops the original column.\n    \n    Parameters:\n        df (pd.DataFrame): The DataFrame containing the date column.\n        column_name (str): The name of the date column to process.\n        prefix (str): The prefix for the new feature columns.\n    \n    Returns:\n        pd.DataFrame: DataFrame with extracted date features.\n    \"\"\"\n    df[column_name] = pd.to_datetime(df[column_name], format='%Y-%m-%d', errors='coerce')\n    df[f'{prefix}_year'] = df[column_name].dt.year\n    df[f'{prefix}_month'] = df[column_name].dt.month\n    df[f'{prefix}_day'] = df[column_name].dt.day\n    return df.drop(columns=[column_name])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train = extract_date_features(df_train, 'date_account_created', 'dac')\ndf_test = extract_date_features(df_test, 'date_account_created', 'dac')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.drop('date_first_booking', inplace = True, axis = 1)\ndf_test.drop('date_first_booking', inplace = True, axis = 1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test.drop('date_first_booking', inplace = True, axis = 1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_timestamp_features(df, column_name):\n    \"\"\"\n    Extracts year, month, day, hour, minute, and second from a timestamp column.\n    \n    Parameters:\n        df (pd.DataFrame): DataFrame containing the timestamp column.\n        column_name (str): Name of the timestamp column to process.\n    \n    Returns:\n        pd.DataFrame: DataFrame with extracted features.\n    \"\"\"\n    # Ensure the column is a string\n    df[column_name] = df[column_name].astype(str)\n    \n    # Extract features\n    df[f'{column_name}_year'] = df[column_name].str[:4].astype(int)\n    df[f'{column_name}_month'] = df[column_name].str[4:6].astype(int)\n    df[f'{column_name}_day'] = df[column_name].str[6:8].astype(int)\n    df[f'{column_name}_hour'] = df[column_name].str[8:10].astype(int)\n    df[f'{column_name}_minute'] = df[column_name].str[10:12].astype(int)\n    df[f'{column_name}_second'] = df[column_name].str[12:14].astype(int)\n    \n    # Optionally, drop the original timestamp column\n    df = df.drop([column_name], axis=1)\n    \n    return df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train = extract_timestamp_features(df_train, 'timestamp_first_active')\ndf_test = extract_timestamp_features(df_test, 'timestamp_first_active')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Sessions:","metadata":{}},{"cell_type":"code","source":"sessions = sessions.groupby(\"user_id\", as_index= False).agg(lambda x:x.tolist())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def convert_to_set(device):\n    device = [str(i) for i in device]\n    device = [re.sub(\"nan\",\"\",i) for i in device]\n    device = \",\".join(set(device))\n    \n    return device\n\ndef convert_the_time(time):\n    \n    float_time = []\n    time = [str(i) for i in time]\n    time = [re.sub(\"nan\",\"\",i) for i in time]\n    \n    for i in time:\n        try:\n            float_time.append(float(i))\n        except ValueError :\n            continue\n\n\n    time = sum(float_time)\n    \n    return time\n\ndef convert_to_string(action):\n    action = [str(i) for i in action]\n    action = [re.sub(\"nan\",\"\",i) for i in action]\n    action = \",\".join(action)\n    \n    return action","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sessions[\"action\"] = sessions[\"action\"].apply(convert_to_string)\nsessions[\"action_type\"] = sessions[\"action_type\"].apply(convert_to_string)\nsessions[\"action_detail\"] = sessions[\"action_detail\"].apply(convert_to_string)\nsessions['device_type'] =sessions['device_type'].apply(convert_to_set)\nsessions['secs_elapsed'] = sessions['secs_elapsed'].apply(convert_the_time)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sessions.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Encoding:","metadata":{}},{"cell_type":"code","source":"X_df_train, X_df_val, y_train, y_val = train_test_split(df_train.drop(columns=['country_destination']), df_train['country_destination'],\n                                                        test_size=0.2, random_state=42, stratify=df_train['country_destination'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Merging With Sessions:","metadata":{}},{"cell_type":"code","source":"X_df_train = X_df_train.merge(sessions, left_on='id', right_on='user_id', how='left')\nX_df_val = X_df_val.merge(sessions, left_on='id', right_on='user_id', how='left')\ndf_test = df_test.merge(sessions, left_on='id', right_on='user_id', how='left')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Age:","metadata":{}},{"cell_type":"code","source":"X_df_train.loc[(X_df_train['age'] >= 100) | (X_df_train['age'] <= 15), 'age'] = np.median(X_df_train['age'].dropna())\nX_df_val.loc[(X_df_val['age'] >= 100) | (X_df_val['age'] <= 15), 'age'] = np.median(X_df_val['age'].dropna())\ndf_test.loc[(df_test['age'] >= 100) | (df_test['age'] <= 15), 'age'] = np.median(df_train['age'].dropna())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def age_binning(age):\n    if 18 < age <= 20:\n        return '18 - 20'\n    elif 20 < age <= 25:\n        return '20 - 25'\n    elif 25 < age <= 30:\n        return '25 - 30'\n    elif 30 < age <= 35:\n        return '30 - 35'\n    elif 35 < age <= 40:\n        return '35 - 40'\n    elif 40 < age <= 45:\n        return '40 - 45'\n    elif 45 < age <= 50:\n        return '45 - 50'\n    elif 50 < age <= 55:\n        return '50 - 55'\n    elif 55 < age <= 60:\n        return '55 - 60'\n    elif 60 < age <= 65:\n        return '60 - 65'\n    elif 65 < age <= 70:\n        return '65 - 70'\n    elif 70 < age <= 75:\n        return '70 - 75'\n    elif 75 < age <= 80:\n        return '75 - 80'\n    elif 80 < age <= 85:\n        return '80 - 85'\n    elif 85 < age <= 90:\n        return '85 - 90'\n    elif 90 < age <= 95:\n        return '90 - 95'\n    elif 95 < age <= 100:\n        return '95 - 100'\n    else:\n        return np.nan\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train['member_age_bins'] = df_train['age'].apply(age_binning)\ndf_test['member_age_bins'] = df_test['age'].apply(age_binning)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_df_train.isna().sum()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_df_val.isna().sum()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Missing Strings:","metadata":{}},{"cell_type":"code","source":"def fill_missing_values(X_df_train, X_df_val, df_test, text_columns, numeric_column):\n    \"\"\"\n    Fills missing values in text columns with 'na' and in a numeric column with 0.\n\n    Args:\n        X_df_train (pd.DataFrame): Training dataframe.\n        X_df_val (pd.DataFrame): Validation dataframe.\n        df_test (pd.DataFrame): Test dataframe.\n        text_columns (list): List of text column names to fill with 'na'.\n        numeric_column (str): Name of numeric column to fill with 0.\n\n    Returns:\n        tuple: Transformed versions of (X_df_train, X_df_val, df_test)\n    \"\"\"\n    for df in [X_df_train, X_df_val, df_test]:\n        df[text_columns] = df[text_columns].fillna(\"na\")\n        df[numeric_column] = df[numeric_column].fillna(0)\n    \n    return X_df_train, X_df_val, df_test","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def tokens(x):\n    return x.split(',')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def fit_transform_tfidf(X_df_train, X_df_val, df_test, columns):\n    \"\"\"\n    Fits a TF-IDF vectorizer on selected text columns of X_df_train and transforms X_df_val & df_test.\n    Adds transformed features to the original dataframes and removes the original text columns.\n\n    Args:\n        X_df_train (pd.DataFrame): Training dataframe.\n        X_df_val (pd.DataFrame): Validation dataframe.\n        df_test (pd.DataFrame): Test dataframe.\n        columns (list): List of text column names to apply TF-IDF.\n\n    Returns:\n        tuple: Transformed versions of (X_df_train, X_df_val, df_test)\n    \"\"\"\n    vectorizers = {}  # Store vectorizers for each column\n    transformed_data = {'train': [], 'val': [], 'test': []}\n\n    for col in columns:\n        vectorizer = TfidfVectorizer(min_df= 10, max_features = 5000, tokenizer = tokens)\n        X_train_tfidf = vectorizer.fit_transform(X_df_train[col].astype(str))  # Fit on training data\n        X_val_tfidf = vectorizer.transform(X_df_val[col].astype(str))  # Transform validation data\n        X_test_tfidf = vectorizer.transform(df_test[col].astype(str))  # Transform test data\n\n        vectorizers[col] = vectorizer\n        transformed_data['train'].append(X_train_tfidf)\n        transformed_data['val'].append(X_val_tfidf)\n        transformed_data['test'].append(X_test_tfidf)\n\n    # Stack transformed columns horizontally\n    X_train_tfidf = hstack(transformed_data['train'])\n    X_val_tfidf = hstack(transformed_data['val'])\n    X_test_tfidf = hstack(transformed_data['test'])\n\n    # Convert sparse matrices to DataFrame\n    train_tfidf_df = pd.DataFrame(X_train_tfidf.toarray(), index=X_df_train.index)\n    val_tfidf_df = pd.DataFrame(X_val_tfidf.toarray(), index=X_df_val.index)\n    test_tfidf_df = pd.DataFrame(X_test_tfidf.toarray(), index=df_test.index)\n\n    # Concatenate new TF-IDF features with original dataframe (excluding original text columns)\n    X_df_train = pd.concat([X_df_train.drop(columns, axis=1), train_tfidf_df], axis=1)\n    X_df_val = pd.concat([X_df_val.drop(columns, axis=1), val_tfidf_df], axis=1)\n    df_test = pd.concat([df_test.drop(columns, axis=1), test_tfidf_df], axis=1)\n\n    return X_df_train, X_df_val, df_test\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"columns_to_vectorize = ['action', 'action_type', 'action_detail']\nX_df_train, X_df_val, df_test = fit_transform_tfidf(X_df_train, X_df_val, df_test, columns_to_vectorize)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Keeping ID\ntrain_id = X_df_train['id']\nval_id = X_df_val['id']\ntest_id = df_test['id']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train = X_df_train.drop(columns=['id', 'user_id'], inplace=False)\nX_val = X_df_val.drop(columns=['id', 'user_id'], inplace=False)\nX_test = df_test.drop(columns=['id', 'user_id'], inplace=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def encode_categorical_features(X_train, X_val, X_test, cat_cols):\n    \"\"\"\n    Encodes categorical features using One-Hot Encoding (OHE) for low-cardinality features\n    and Label Encoding for high-cardinality features.\n\n    Parameters:\n        X_train (DataFrame): Training data\n        X_val (DataFrame): Validation data\n        X_test (DataFrame): Test data\n        cat_cols (list): List of categorical column names\n\n    Returns:\n        X_train, X_val, X_test (DataFrame): Transformed datasets\n        label_encoders (dict): Dictionary of label encoders for high-cardinality features\n    \"\"\"\n\n    # Ensure categorical columns exist in all datasets\n    cat_cols = [col for col in cat_cols if col in X_train.columns]\n\n    # Separate columns based on the number of unique categories\n    one_hot_cols = [col for col in cat_cols if X_train[col].nunique() < 5]\n    label_encode_cols = [col for col in cat_cols if X_train[col].nunique() >= 5]\n\n    # One-Hot Encoding for low-cardinality features\n    if one_hot_cols:\n        ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n        X_train_ohe = pd.DataFrame(ohe.fit_transform(X_train[one_hot_cols]), \n                                   columns=ohe.get_feature_names_out(one_hot_cols))\n        X_val_ohe = pd.DataFrame(ohe.transform(X_val[one_hot_cols]), \n                                 columns=ohe.get_feature_names_out(one_hot_cols))\n        X_test_ohe = pd.DataFrame(ohe.transform(X_test[one_hot_cols]), \n                                  columns=ohe.get_feature_names_out(one_hot_cols))\n        # Drop original categorical columns and merge OHE results\n        X_train = X_train.drop(columns=one_hot_cols, errors='ignore').reset_index(drop=True).join(X_train_ohe)\n        X_val = X_val.drop(columns=one_hot_cols, errors='ignore').reset_index(drop=True).join(X_val_ohe)\n        X_test = X_test.drop(columns=one_hot_cols, errors='ignore').reset_index(drop=True).join(X_test_ohe)\n\n    # Label Encoding for high-cardinality features\n    label_encoders = {}\n    for col in label_encode_cols:\n        le = LabelEncoder()\n        X_train[col] = le.fit_transform(X_train[col].astype(str))\n        X_val[col] = X_val[col].map(lambda x: le.transform([x])[0] if x in le.classes_ else -1)\n        X_test[col] = X_test[col].map(lambda x: le.transform([x])[0] if x in le.classes_ else -1)\n        label_encoders[col] = le  # Store encoder for inverse transform if needed\n\n    return X_train, X_val, X_test, label_encoders\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cat_cols = ['gender', 'signup_method', 'language', 'affiliate_channel', \n            'affiliate_provider', 'first_affiliate_tracked', 'signup_app', \n            'first_device_type', 'first_browser', 'member_age_bins', 'device_type',]\n\n# Encode categorical features for all datasets\nX_train, X_val, X_test, label_encoders = encode_categorical_features(X_train, X_val, X_test, cat_cols)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Imbalance","metadata":{}},{"cell_type":"code","source":"# Plot the distribution of the target variable\nsns.countplot(x=y_train)\nplt.title('Class Distribution in y_train')\nplt.xlabel('Class')\nplt.ylabel('Count')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_distribution = y_train.value_counts()\n\n# Get the proportion of each class\nclass_proportions = y_train.value_counts(normalize=True)*100\nprint(class_proportions)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label_encoder = LabelEncoder()\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_val_encoded = label_encoder.transform(y_val)\n\nprint(\"Encoded y_train:\", y_val_encoded[:5])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_test.drop(['member_age_bins'], axis = 1, inplace = True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model:","metadata":{}},{"cell_type":"code","source":"xgb = XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.5, gamma=0, gpu_id=-1,\n              importance_type='gain', interaction_constraints=None,\n              learning_rate=0.3, max_delta_step=0, max_depth=6,\n              min_child_weight=1, missing=np.nan, monotone_constraints=None,\n              n_estimators=25, n_jobs=0, num_parallel_tree=1,\n              objective='multi:softprob', random_state=0, reg_alpha=0,\n              reg_lambda=1, scale_pos_weight=None, seed=0, subsample=0.5,\n              tree_method=None, validate_parameters=False, verbosity=None)\n\nxgb.fit(X_train, y_train_encoded)\n\ny_pred = xgb.predict_proba(X_test)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred_train = xgb.predict_proba(X_train)\ny_pred_val = xgb.predict_proba(X_val)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_ndcg(y_true, y_pred, k=5):\n    \"\"\"\n    Computes the NDCG@k score for multi-class classification.\n\n    Parameters:\n        y_true (array-like): Ground truth labels, must be encoded as integers.\n        y_pred (array-like): Predicted probabilities (output of predict_proba).\n        k (int): The number of top predictions to consider for NDCG calculation.\n    \n    Returns:\n        float: The NDCG@k score.\n    \"\"\"\n    # Convert y_true to binary indicator format\n    label_binarizer = LabelBinarizer()\n    y_true_binarized = label_binarizer.fit_transform(y_true)\n\n    # Compute NDCG@k\n    ndcg_score_value = ndcg_score(y_true_binarized, y_pred, k=k)\n\n    return ndcg_score_value","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ndcg_train_score = compute_ndcg(y_train_encoded, y_pred_train, k=5)\nprint(f\"NDCG@5 Score on Training Data: {ndcg_train_score:.4f}\")\n\nndcg_val_score = compute_ndcg(y_val_encoded, y_pred_val, k=5)\nprint(f\"NDCG@5 Score on Val Data: {ndcg_val_score:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Submission:","metadata":{}},{"cell_type":"code","source":"ids = []\ncts = []\nfor i in range(len(test_id)):\n    idx = test_id[i]\n    ids += [idx] * 5\n    cts += label_encoder.inverse_transform(np.argsort(y_pred[i])[::-1])[:5].tolist()\n\nsub = pd.DataFrame(np.column_stack((ids, cts)), columns=['id', 'country'])\nsub.to_csv('submission.csv',index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}